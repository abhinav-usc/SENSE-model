# -*- coding: utf-8 -*-
"""Predicting Lancester Norms.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yQeSpATNpHuE4V-nsvfL-C8k_5Na9Pb3

#Extracting Sensorimotor Information from Word Embeddings
This codebase explores the relationship between word embeddings and Lancaster Sensorimotor Norms by analyzing 40,000 phrases across 11 modalities and building a model to extract sensorimotor information from any word, revealing how language encodes sensory experiences.

## 1. Importing dataset and libraries
"""

from google.colab import drive
drive.mount('/content/drive')

# For Clip
# ! pip install ftfy regex tqdm
# ! pip install git+https://github.com/openai/CLIP.git

import numpy as np
import torch
import torch.nn as nn
import pandas as pd
import pickle
import matplotlib.pyplot as plt
from google.colab import drive
from sklearn.model_selection import train_test_split
from torch.utils.data import Subset
# import gensim.downloader as api
# from gensim.models import KeyedVectors
import torch.optim as optim
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
from sklearn.cluster import KMeans
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics.pairwise import cosine_similarity
from heapq import nlargest
from transformers import BertTokenizer, BertModel
from transformers import RobertaTokenizer, RobertaModel
from torch.utils.data import DataLoader, TensorDataset

"""## Set data type"""

data_type = "bert"
# change to glove, bert, word2vec, bert_roberta, clip or intersection appropriately

"""## Retrieving Data"""

def set_data(embedding_type):
  data_location = ""
  if embedding_type == 'word2vec':
    data_location = '/content/drive/My Drive/Lancaster/data.pt'
  elif embedding_type == 'glove':
    data_location = '/content/drive/My Drive/Lancaster/data_glove.pt'
  elif embedding_type == 'bert':
    data_location = '/content/drive/My Drive/Lancaster/cls_tokens.pt'
  elif embedding_type == 'bert_roberta':
    data_location = '/content/drive/My Drive/Lancaster/cls_tokens_roberta.pt'
  elif embedding_type == 'word2vec_intersection':
    data_location = "/content/drive/My Drive/Lancaster/intersect_word2vec.pt"
  elif embedding_type == 'glove_intersection':
    data_location = "/content/drive/My Drive/Lancaster/intersect_glove.pt"
  elif embedding_type == 'bert_intersection':
    data_location = "/content/drive/My Drive/Lancaster/intersect_cls_tokens.pt"
  elif embedding_type == 'clip':
    data_location = "/content/drive/My Drive/Lancaster/clip_data.pt"
  elif embedding_type == 'blip':
    data_location = "/content/drive/My Drive/Lancaster/blip_data.pt"
  elif embedding_type == 'flan_t5':
    data_location = "/content/drive/My Drive/Lancaster/flan_t5_data_flan.pt"
  elif embedding_type == 'bert_bpe':
    data_location = "/content/drive/My Drive/Lancaster/bpe_tokens.pt"
  return torch.load(data_location, weights_only=False)

"""## Splitting Data"""

# Get data based on type
data = set_data(data_type)

# Separate the features (X) and target variable (Y)
input = data['embedding']
target = data['sensorimotor']
# Split the data into training and testing sets (e.g., 70% train, 15% validation, 15% test)
X_train, X_temp, Y_train, Y_temp = train_test_split(input, target, test_size=0.3, random_state=42)

# Now split the temp set into test and dev sets (e.g., 50% test, 50% dev from the temp set)
X_test, X_dev, Y_test, Y_dev = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)

len(data)
device = "cuda" if torch.cuda.is_available() else "cpu"

print(data['embedding'][0].shape)

#prepare dataset
from torch.utils.data import Dataset

class VectorDataset(Dataset):
    def __init__(self, inputs, targets):
        # Convert each vector to a numpy array and stack them into a 2D numpy array
        inputs = np.stack([np.asarray(vec) for vec in inputs])
        targets = np.stack([np.asarray(vec) for vec in targets])

        # Convert to PyTorch tensors
        self.inputs = torch.from_numpy(inputs).float()
        self.targets = torch.from_numpy(targets).float()  # use .long() for integer labels in classification


    def __len__(self):
        return len(self.inputs)

    def __getitem__(self, idx):
        input_vector = self.inputs[idx]
        target_vector = self.targets[idx]
        return input_vector, target_vector

"""## Analyze Train Data"""

# Find correlation between gustatory and olfactory and others
import seaborn as sns

data_analyze = pd.read_csv('/content/drive/My Drive/Lancaster/lancaster-ensorimotor-norms.csv')


# Calculate the correlation matrix
correlation_matrix = data_analyze[['Gustatory.mean','Olfactory.mean', 'Auditory.mean', 'Haptic.mean', 'Interoceptive.mean', 'Visual.mean', 'Mouth.mean','Foot_leg.mean',  'Hand_arm.mean',  'Head.mean', 'Torso.mean']].corr()

print("\nCorrelation Matrix:")
print(correlation_matrix)

# Plot the correlation matrix
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Correlation Matrix')
plt.show()

# Using Matplotlib hist() function
plt.figure(figsize=(8, 6))
plt.hist(data_analyze['Torso.mean'], bins=10, color='skyblue', edgecolor='black')
plt.title('Frequency Chart (Histogram) of Torso')
plt.xlabel('Values')
plt.ylabel('Frequency')
plt.grid(False)
plt.show()

"""## Text analysis experiment"""

file_path = "/content/drive/My Drive/Lancaster/word_vectors_model.bin"

# word_vectors = api.load("word2vec-google-news-300")

# word_vectors.save(file_path)

word_vectors = KeyedVectors.load(file_path)

def convert_gensim_to_pytorch(gensim_model):
    vocab_size = len(gensim_model.index_to_key)
    vector_size = gensim_model.vector_size

    # Initialize a PyTorch embedding layer
    embedding = torch.nn.Embedding(vocab_size, vector_size)

    # Fill the embedding layer with the gensim weights
    for i, word in enumerate(gensim_model.index_to_key):
        embedding.weight.data[i] = torch.tensor(gensim_model[word])

    return embedding

#Load Model

PATH = ""

data_type = 'word2vec'
if data_type == 'word2vec':
  PATH = "/content/drive/My Drive/Lancaster/NNmodel.pt"
elif data_type == 'glove':
  PATH = "/content/drive/My Drive/Lancaster/NNmodel_glove.pt"
elif data_type == 'bert':
  PATH = "/content/drive/My Drive/Lancaster/NNmodel_bert.pt"
elif data_type == 'word2vec_intersection':
  PATH = "/content/drive/My Drive/Lancaster/word2vec_intersection.pt"
elif data_type == 'glove_intersection':
  PATH = "/content/drive/My Drive/Lancaster/glove_intersection.pt"
elif data_type == 'bert_intersection':
  PATH = "/content/drive/My Drive/Lancaster/bert_intersection.pt"



neural_model = Net(64, 128, data_type)
neural_model.load_state_dict(torch.load(PATH))

# Analysis experiment

pytorch_embedding = convert_gensim_to_pytorch(word_vectors)

phrase = """Imagine standing in front of the Mona Lisa, a masterpiece painted by Leonardo da Vinci. The painting is relatively small, yet it commands an immense presence. As you gaze upon it, the first thing that captures your attention is her enigmatic smile, a subtle, almost elusive expression that seems to change as you move around the room.
Her eyes, framed by delicate brows, hold a mysterious gaze, following you with an uncanny sense of life. They are deep, dark, and seemingly all-knowing, drawing you into the secrets she might be hiding. Her smooth, pale skin has a soft, luminous quality, almost like porcelain, accentuated by the gentle shadows and highlights crafted by da Vinci’s skillful use of sfumato.
Her hair, dark and wavy, cascades down in soft, natural curls, blending seamlessly with the background. She wears a simple, yet elegant, dark dress with fine details on the sleeves, the folds and fabric rendered with meticulous precision, giving a sense of texture and weight.
The background is equally mesmerizing, a fantastical landscape that seems both real and otherworldly. Rolling hills, winding paths, and serene water bodies stretch out behind her, painted in soft, muted tones that contrast with the warm hues of her complexion. The hazy, atmospheric perspective da Vinci employs creates a sense of depth and distance, making the scene appear almost ethereal.
The play of light and shadow throughout the painting is masterful, lending a three-dimensional quality to her figure and face. The overall composition, with her centered and framed by the serene landscape, exudes a calm, balanced harmony.
As you take in the details, the painting feels almost alive, its beauty and mystery captivating your senses and leaving a lasting impression of timeless elegance and intrigue.
"""


words = phrase.split()

data = pd.DataFrame()

data['word'] = np.empty(len(words), dtype=str)
data['embedding'] = np.empty(len(words), dtype=object)

data_copy = {}
df = pd.DataFrame(data_copy)

for phrase in words:
  try:
        # split phrase into words
        words = phrase.split()
        average_embedding = torch.zeros(pytorch_embedding.embedding_dim)
        valid_word_count = 0
        for word in words:
          word = word.strip('.,!?:')
          word_index = word_vectors.key_to_index[word.lower()]  # Get the index of the word
          word_index_tensor = torch.tensor(word_index)  # Convert the index to a PyTorch tensor
          word_embedding = pytorch_embedding(word_index_tensor)  # Get the word embedding
          average_embedding += word_embedding
          valid_word_count += 1

        if valid_word_count > 0:
          average_embedding = average_embedding / valid_word_count
        else:
          average_embedding = None  # Handle case with no valid words

        # construct vector for sensorimotor

        new_row = {'word': word,'embedding': average_embedding.detach().numpy()}
        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)

  except KeyError:
        # Handle the case where the word is not in the word_vectors vocabulary
        # You can choose to skip it or use a default embedding in such cases
        print(f"Word '{word}' not found in the vocabulary.")


data = df

sensorimotor = [0,0,0,0,0,0,0,0,0,0,0]
count = 0
for index, row in df.iterrows():
  word = row['word']
  embedding = row['embedding']
  embedding_tensor = torch.tensor(embedding, dtype=torch.float32)

  sensorimotor_cur = neural_model(embedding_tensor).tolist()
  sensorimotor = [x + y for x, y in zip(sensorimotor, sensorimotor_cur)]
  count +=1

sensorimotor = [x/count for x in sensorimotor]
print(sensorimotor)

"""##Neural Network Model"""

# creating the neural network
class Net(nn.Module):
    def __init__(self, d1, d2, embedding_type):
        super(Net, self).__init__()
        if embedding_type == 'word2vec' or embedding_type == 'word2vec_intersection':
          input_size = 300
        elif embedding_type == 'glove' or embedding_type == 'glove_intersection':
          input_size = 100
        elif embedding_type == 'bert' or embedding_type =='bert_bpe' or embedding_type == 'bert_intersection':
          input_size = 768
        elif embedding_type == 'bert_roberta':
          input_size = 768
        elif embedding_type == 'clip':
          input_size = 512
        elif embedding_type == 'blip':
          input_size = 768
        elif embedding_type == 'flan_t5':
          input_size = 2048
        elif embedding_type == 'sensorimotor_to_bert_cls':
          input_size = 11
        output_size = 11
        if embedding_type == 'sensorimotor_to_bert_cls':
          output_size = 768
        self.input_dim = input_size
        self.fc1 = nn.Linear(input_size, d1)  # input vector size is 300/100/768
        self.fc2 = nn.Linear(d1, d2)
        self.fc3 = nn.Linear(d2, output_size)  # assuming output vector size is 11 for sensorimotor
        self.act = nn.ReLU()
        self.final_act = nn.Sigmoid()  # or use clamp

    def forward(self, x):
        x = self.act(self.fc1(x))
        x = self.act(self.fc2(x))
        x = self.fc3(x)
        # x = self.final_act(x)  # Uncomment if Sigmoid activation is needed at the final layer
        # x = torch.clamp(x, min= 0, max=1)

        return x

neural_model = Net(64, 128, data_type)

"""## Average Model"""

def avg_model(inputs):
  avg = np.zeros_like(Y_train.iloc[0])
  for item in Y_train:  # train_loader is your DataLoader containing training data
      avg += item
  avg/= len(Y_train)
  outputs = []
  for input in inputs:
    outputs.append(avg)
  outputs = torch.tensor(outputs)

  return outputs

"""## KNN Model"""

# Data for KNN
X_temp = X_dev[0:int(len(X_dev)/10)]
# Specify the file path where you want to save the matrix
file_path = ''
if data_type == 'word2vec':
  file_path = '/content/drive/My Drive/Lancaster/cosine_similarity.npy'
elif data_type == 'glove':
  file_path = '/content/drive/My Drive/Lancaster/cosine_similarity_glove.npy'
elif data_type == 'bert':
  file_path = '/content/drive/My Drive/Lancaster/cosine_similarity_bert.npy'
elif data_type == 'word2vec_intersection':
  file_path = "/content/drive/My Drive/Lancaster/cosine_similarity_intersect_word2vec.pt.npy"
elif data_type == 'glove_intersection':
  file_path = "/content/drive/My Drive/Lancaster/cosine_similarity_intersect_glove.pt.npy"
elif data_type == 'bert_intersection':
  file_path = "/content/drive/My Drive/Lancaster/cosine_similarity_intersect_cls_tokens.pt.npy"
# Save the cosine_sim matrix to the specified file path
# np.save(file_path, cosine_sim)

cosine_sim = np.load(file_path)

def model_knn(inputs, k=5):
  outputs = torch.tensor([])
  for input in inputs:
    index = 0
    for id, item in enumerate(X_temp):
      if np.array_equal(input,item):
        index = id
        break
    cosine_sim_of_input = cosine_sim[index]
    temp = sorted(cosine_sim_of_input)[-k:]
    res = []
    for ele in temp:
      # encapsulating elements with index using index()
      index = 0
      for id, item in enumerate(cosine_sim_of_input):
         if np.array_equal(item,ele):
            index = id
            break
      res.append((index, ele))
    output = np.zeros(len(Y_train.iloc[0]))
    sum_sim = 0
    for entry in res:
      train_idx, sim = entry
      sim = 0.5 * sim + 0.5
      output += np.array(Y_train.iloc[train_idx]) * sim
      sum_sim += sim
    output *= (1/sum_sim)
    output = torch.tensor([output])
    outputs = torch.cat((outputs, output), dim=0)
  return outputs

"""## Neural Network Training"""

criterion = nn.MSELoss()
optimizer = optim.Adam(neural_model.parameters(), lr=0.001)
num_epochs = 50

# X_train_inverse = Y_train
# Y_train_inverse = X_train
dataset = VectorDataset(X_train, Y_train)

from torch.utils.data import DataLoader
train_loader = DataLoader(dataset, batch_size=128, shuffle=True)

# # Training
i = 0
for epoch in range(num_epochs):  # num_epochs is the number of epochs
    for dat in train_loader:  # train_loader is your DataLoader containing training data
        inputs, targets = dat
        optimizer.zero_grad()
        outputs = neural_model(inputs)
        loss = criterion(outputs, targets)
        if(i%100 == 0):
          print(loss.item())
        i+=1
        loss.backward()
        optimizer.step()

# # Save model
# criterion = nn.MSELoss()
# PATH = ""

# if data_type == 'word2vec':
#   PATH = "/content/drive/My Drive/Lancaster/NNmodel.pt"
# elif data_type == 'glove':
#   PATH = "/content/drive/My Drive/Lancaster/NNmodel_glove.pt"
# elif data_type == 'bert':
#   PATH = "/content/drive/My Drive/Lancaster/NNmodel_bert.pt"
# elif data_type == 'bert_roberta':
#   PATH = "/content/drive/My Drive/Lancaster/NNmodel_bert_roberta.pt"
# elif data_type == 'word2vec_intersection':
#   PATH = "/content/drive/My Drive/Lancaster/word2vec_intersection.pt"
# elif data_type == 'glove_intersection':
#   PATH = "/content/drive/My Drive/Lancaster/glove_intersection.pt"
# elif data_type == 'bert_intersection':
#   PATH = "/content/drive/My Drive/Lancaster/bert_intersection.pt"
# elif data_type == 'clip':
#   PATH = "/content/drive/My Drive/Lancaster/clip.pt"
# elif data_type == 'blip':
#   PATH = "/content/drive/My Drive/Lancaster/blip.pt"
# elif data_type == 'flan_t5':
#   PATH = "/content/drive/My Drive/Lancaster/flan_t5_model_state.pt"
# elif data_type == 'sensorimotor_to_bert_cls':
#   PATH = "/content/drive/My Drive/Lancaster/NNmodel_sensorimotor_to_bert_cls.pt"
# elif data_type == 'bert_bpe':
#   PATH = "/content/drive/My Drive/Lancaster/bpe_tokens_to_sensorimotor.pt"
# torch.save(neural_model.state_dict(), PATH)

"""##Load Model

"""

PATH = ""

# data_type = 'sensorimotor_to_bert_cls'


# if data_type == 'word2vec':
#   PATH = "/content/drive/My Drive/Lancaster/NNmodel.pt"
# elif data_type == 'glove':
#   PATH = "/content/drive/My Drive/Lancaster/NNmodel_glove.pt"
# elif data_type == 'bert':
#   PATH = "/content/drive/My Drive/Lancaster/NNmodel_bert.pt"
# elif data_type == 'bert_roberta':
#   PATH = "/content/drive/My Drive/Lancaster/NNmodel_bert_roberta.pt"
# elif data_type == 'clip':
#   PATH = "/content/drive/My Drive/Lancaster/clip.pt"
# elif data_type == 'word2vec_intersection':
#   PATH = "/content/drive/My Drive/Lancaster/word2vec_intersection.pt"
# elif data_type == 'glove_intersection':
#   PATH = "/content/drive/My Drive/Lancaster/glove_intersection.pt"
# elif data_type == 'bert_intersection':
#   PATH = "/content/drive/My Drive/Lancaster/bert_intersection.pt"
# elif data_type == 'sensorimotor_to_bert_cls':
#   PATH = "/content/drive/My Drive/Lancaster/NNmodel_sensorimotor_to_bert_cls.pt"


# neural_model = Net(64, 128, data_type)
# neural_model.load_state_dict(torch.load(PATH))


data_type = 'bert'
if data_type == 'word2vec':
  PATH = "/content/drive/My Drive/Lancaster/NNmodel.pt"
elif data_type == 'glove':
  PATH = "/content/drive/My Drive/Lancaster/NNmodel_glove.pt"
elif data_type == 'bert':
  PATH = "/content/drive/My Drive/Lancaster/NNmodel_bert.pt"
elif data_type == 'bert_roberta':
  PATH = "/content/drive/My Drive/Lancaster/NNmodel_bert_roberta.pt"
elif data_type == 'clip':
  PATH = "/content/drive/My Drive/Lancaster/clip.pt"
elif data_type == 'word2vec_intersection':
  PATH = "/content/drive/My Drive/Lancaster/word2vec_intersection.pt"
elif data_type == 'glove_intersection':
  PATH = "/content/drive/My Drive/Lancaster/glove_intersection.pt"
elif data_type == 'bert_intersection':
  PATH = "/content/drive/My Drive/Lancaster/bert_intersection.pt"
elif data_type == 'sensorimotor_to_bert_cls':
  PATH = "/content/drive/My Drive/Lancaster/NNmodel_sensorimotor_to_bert_cls.pt"

neural_model = Net(64, 128, 'bert')
neural_model.load_state_dict(torch.load(PATH))

"""## Inverse model to convert backwards template"""

# Inverse

# Extract weights and biases from the trained model
fc1_weight = neural_model.fc1.weight.data
fc1_bias = neural_model.fc1.bias.data
fc2_weight = neural_model.fc2.weight.data
fc2_bias = neural_model.fc2.bias.data
fc3_weight = neural_model.fc3.weight.data
fc3_bias = neural_model.fc3.bias.data

fc1_weight_pinv = torch.pinverse(fc1_weight)
fc2_weight_pinv = torch.pinverse(fc2_weight)
fc3_weight_pinv = torch.pinverse(fc3_weight)

import torch.nn.functional as F

def reverse_pass(output):
    # convert output to proper format
    output = torch.tensor(output, dtype=torch.float32)
    # Reverse the third layer
    x = F.linear(output - fc3_bias, fc3_weight_pinv)

    # Reverse the activation function
    x = F.relu(x)

    # Reverse the second layer
    x = F.linear(x - fc2_bias, fc2_weight_pinv)

    # Reverse the activation function
    x = F.relu(x)

    # Reverse the first layer
    x = F.linear(x - fc1_bias, fc1_weight_pinv)

    return x
# Assuming some output tensor called `sample_output`

{'Auditory':0, 'Gustatory': 0,	'Haptic': 0,
                        'Interoceptive': 0,	'Olfactory': 0,	'Visual': 0,
                        'Foot_leg' : 0,	'Hand_arm':0,	'Head': 0,
                        'Mouth':	0, 'Torso': 0}


sample_output = data['sensorimotor'][29889]  # Replace with actual output tensor

# Predict the input
predicted_input = reverse_pass(sample_output)
# print("Predicted Input:", predicted_input)

arr = np.array(predicted_input)

# Running inverse model's output thru orginal model as input to verify
input = torch.tensor(arr, dtype=torch.float32)
ar = neural_model(input)
b_tensor = data['sensorimotor'][29889]

a = ar.detach().numpy()
b = np.array(b_tensor)

# Another checker with original data(comment out if using above)
a = arr
b = data['embedding'][29889]

# Cosine similarity
from numpy import dot
from numpy.linalg import norm

# cos_sim = dot(a, b)/(norm(a)*norm(b))
# print(cos_sim)

"""## Freezing weights to learn input from outputs"""

tokenizer      = BertTokenizer.from_pretrained("bert-base-uncased")
bert_model     = BertModel.from_pretrained("bert-base-uncased")

"""## Backwards Prop Approach"""

def get_cls_from_sensorimotor(sensorimotor_norm,
                               bert_model,
                               proj_model,
                               n_iter=1000,
                               lam=1e-4,
                               n_restarts=5,
                               device=None):

    device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # freeze & place models
    proj_model.eval().to(device)
    bert_model.eval().to(device)
    for p in proj_model.parameters(): p.requires_grad = False

    # static helpers
    W = bert_model.embeddings.word_embeddings.weight
    target = (torch.as_tensor(sensorimotor_norm, dtype=torch.float32)
                    .unsqueeze(0)
                    .to(device))

    criterion = torch.nn.MSELoss()

    best_z, best_loss = None, float('inf')

    for _ in range(n_restarts):
        # random start INSIDE the embedding space
        rand_idx = torch.randint(len(W), (1,), device=device)
        z_init   = W[rand_idx].clone().detach()

        z = torch.nn.Parameter(z_init)
        opt = torch.optim.Adam([z], lr=0.1)

        for _ in range(n_iter):
            opt.zero_grad()

            pred = proj_model(z)
            mse  = criterion(pred, target)
            # print("mse: ", mse)

            reg  = lam * z.pow(2).mean()
            loss = mse + reg
            loss.backward()
            opt.step()

        if loss.item() < best_loss:
            best_loss, best_z = loss.item(), z.detach().clone()

    return best_z, best_loss

def get_token_from_cls(cls_embedding, bert_model, tokenizer, n_iter=1000,lr=0.01, lam=.01, map_to_real_token=True, n_restarts=1):
  # freeze weights
  device = "cuda" if torch.cuda.is_available() else "cpu"
  bert_model.eval()
  for p in bert_model.parameters():
      p.requires_grad = False

  # parameters
  W = bert_model.get_input_embeddings().weight
  # target CLS vector → (1, D) on device
  target_cls = torch.as_tensor(cls_embedding, dtype=torch.float32, device=device).unsqueeze(0)
  # fixed CLS / SEP embeddings  (1, D)
  cls_embed = W[tokenizer.cls_token_id].unsqueeze(0)
  sep_embed = W[tokenizer.sep_token_id].unsqueeze(0)

  best_z, best_loss = None, float('inf')

  # initialise z as an existing token embedding
  for _ in range(n_restarts):

    z_init = W[torch.randint(len(W), (1,), device=device)].clone().detach()
    z = torch.nn.Parameter(z_init)
    # z2_init = W[torch.randint(len(W), (1,), device=device)].clone().detach()
    # z2 = torch.nn.Parameter(z2_init)

    opt = torch.optim.Adam([z], lr=lr)
    criterion = torch.nn.MSELoss()

    for _ in range(n_iter):
      opt.zero_grad()

      # build sequence embedding: [CLS] z [SEP]
      embeds = torch.cat([cls_embed, z, sep_embed], dim=0).unsqueeze(0)
      pred_outputs = bert_model(inputs_embeds=embeds, output_hidden_states=True)
      predicted_cls = pred_outputs.hidden_states[-1][:, 0, :]

      mse = criterion(predicted_cls, target_cls)
      # print("mse: ", mse)

      # Light L2 - keeps z from exploding
      reg = lam * (z.pow(2).mean())
      loss = mse + reg
      loss.backward()
      opt.step()
    if loss.item() < best_loss:
            best_loss, best_z = loss.item(), z.detach().clone()


  token_ids = None
  if map_to_real_token:
    dists = torch.cdist(best_z.detach(), W)                   # (1, V)
    k = 5                                           # how many neighbours you want
    nearest_dists, nearest_ids = dists.topk(
        k, dim=1, largest=False                    # smallest = nearest
    )                                              # both tensors are shape (1, k)

    token_ids = nearest_ids.squeeze(0).tolist()
  tokens = tokenizer.convert_ids_to_tokens(token_ids)

  return best_z.detach().squeeze(0), tokens, loss.item()

def get_token_from_sensorimotor(sensorimotor_norm,
                               bert_model,
                               tokenizer,
                               proj_model,
                               n_iter=1000,
                               lr=0.01,
                               lam=1e-3,
                               n_restarts=1, k=5):
  device = "cuda" if torch.cuda.is_available() else "cpu"

  # freeze & place models
  proj_model.eval().to(device)
  bert_model.eval().to(device)

  for p in proj_model.parameters(): p.requires_grad = False
  for p in bert_model.parameters(): p.requires_grad = False


  # static helpers
  W_cls = bert_model.embeddings.word_embeddings.weight
  W_token = bert_model.get_input_embeddings().weight

  target_lancaster = (torch.as_tensor(sensorimotor_norm, dtype=torch.float32)
                  .unsqueeze(0)
                  .to(device))

  criterion = torch.nn.MSELoss()
  best_token, best_loss = None, float('inf')


  # fixed CLS / SEP embeddings  (1, D)
  cls_embed = W_token[tokenizer.cls_token_id].unsqueeze(0)
  sep_embed = W_token[tokenizer.sep_token_id].unsqueeze(0)


  for _ in range(n_restarts):
      # random start INSIDE the embedding space
      z_init = W_token[torch.randint(len(W_token), (1,), device=device)].clone().detach()
      z = torch.nn.Parameter(z_init)
      opt = torch.optim.Adam([z], lr=lr)

      for _ in range(n_iter):
          opt.zero_grad()

          # build sequence embedding: [CLS] z [SEP]
          embeds = torch.cat([cls_embed, z, sep_embed], dim=0).unsqueeze(0)
          pred_outputs = bert_model(inputs_embeds=embeds, output_hidden_states=True)
          predicted_cls = pred_outputs.hidden_states[-1][:, 0, :]
          predicted_lancaster = proj_model(predicted_cls)

          mse  = criterion(predicted_lancaster, target_lancaster)
          # print("mse: ", mse)

          reg  = lam * z.pow(2).mean() + lam * z1.pow(2).mean()
          loss = mse + reg
          loss.backward()
          opt.step()

      if loss.item() < best_loss:
          best_loss, best_token = loss.item(), z.detach().clone()

  # Get the tokens from embeddings
  dists = torch.cdist(best_token.detach(), W_token)                   # (1, V)
                                     # how many neighbours you want
  nearest_dists, nearest_ids = dists.topk(
      k, dim=1, largest=False                    # smallest = nearest
  )                                              # both tensors are shape (1, k)

  token_ids = nearest_ids.squeeze(0).tolist()
  distances = nearest_dists.squeeze(0).tolist()


  return tokenizer.convert_ids_to_tokens(token_ids), distances, best_loss

"""## Bruteforce Approach"""

device = "cuda" if torch.cuda.is_available() else "cpu"

tokenizer   = BertTokenizer.from_pretrained("bert-base-uncased")
bert_model  = BertModel.from_pretrained("bert-base-uncased").to(device).eval()

neural_model = neural_model.to(device).eval()   # <--- add this line

W_tokens = bert_model.get_input_embeddings().weight.to(device)
cls_embed = W_tokens[tokenizer.cls_token_id].unsqueeze(0)
sep_embed = W_tokens[tokenizer.sep_token_id].unsqueeze(0)

batch_size = 512
sensorimotor_rows = []

# ---------------- inference loop ----------------
with torch.no_grad():
    n_tokens = W_tokens.shape[0]
    for i in range(0, n_tokens, batch_size):
        print(f"{(i/n_tokens)*100:.2f}% done")

        token_batch = W_tokens[i:i+batch_size]                      # (B, hidden)
        token_batch = token_batch.unsqueeze(1)                      # (B, 1, hidden)

        cls_rep = cls_embed.repeat(token_batch.size(0), 1, 1)      # (B, 1, hidden)
        sep_rep = sep_embed.repeat(token_batch.size(0), 1, 1)      # (B, 1, hidden)

        embeds = torch.cat([cls_rep, token_batch, sep_rep], dim=1)  # (B, 3, hidden)

        outputs = bert_model(inputs_embeds=embeds,
                             output_hidden_states=True)
        cls_out = outputs.hidden_states[-1][:, 0, :]                # (B, hidden)

        lancaster_pred = neural_model(cls_out)                      # ← devices match

        for j, pred in enumerate(lancaster_pred):
            sensorimotor_rows.append({
                "token_id": i + j,
                "sensorimotor": pred.detach().cpu()
            })

# ---------------- save ----------------
df = pd.DataFrame(sensorimotor_rows)
torch.save(df, "/content/drive/My Drive/Lancaster/all_tokens_sensorimotor.pt")

from torch.serialization import add_safe_globals

# COMMON_EN = set(pd.read_csv(
#       '/content/drive/My Drive/Lancaster/english_words.txt',
#       header=None,
#       names=["word"],
#       engine="python"
#   )["word"].tolist())

#Bruteforce approach -> try all tokens
def get_token_from_sensorimotor_bruteforce(sensorimotor_norm,
                               bert_model,
                               tokenizer,
                               proj_model,
                               n_iter=1000,
                               lr=0.01,
                               lam=1e-3,
                               n_restarts=1, k=5):



  path = '/content/drive/My Drive/Lancaster/all_tokens_sensorimotor.pt'

  add_safe_globals([pd.DataFrame])          # allow-list DataFrame
  all_tokens_sensorimotor_df = torch.load(path, weights_only=False) # now succeeds
  device = "cuda" if torch.cuda.is_available() else "cpu"


  # df["sensorimotor"] is a column of tensors; stack them into one big matrix
  sm_matrix = torch.stack(all_tokens_sensorimotor_df["sensorimotor"].tolist()).to(device)   # (V, D)
  token_ids = all_tokens_sensorimotor_df["token_id"].tolist() if "token_id" in all_tokens_sensorimotor_df.columns else list(range(len(all_tokens_sensorimotor_df)))

  # 2.  Prepare the query vector
  sensorimotor_norm = torch.as_tensor(sensorimotor_norm,
                                      dtype=sm_matrix.dtype,
                                      device=device).unsqueeze(0)   # (1, D)

  # 3.  Compute distances and take top-k nearest
  dists = torch.cdist(sensorimotor_norm, sm_matrix)                 # (1, V)
  print((dists.shape))
  # filter tokens that are in english_words
  keep_idx = []
  keep_token_ids = []
  for idx, tid in enumerate(token_ids):
        tok = tokenizer.convert_ids_to_tokens(tid)
        if tok.lower() not in COMMON_EN:
            keep_idx.append(idx)
            keep_token_ids.append(tid)

  dists = dists[:, keep_idx]

  # get nearest k dists and the corresponding ids
  nearest_dists, nearest_pos = dists.topk(k=min(k, dists.size(1)), dim=1, largest=False)

  ids = [keep_token_ids[i] for i in nearest_pos.squeeze(0).tolist()]
  tokens = tokenizer.convert_ids_to_tokens(ids)
  distances = nearest_dists.squeeze(0).tolist()

  return tokens, distances, 0

"""## Getting weighted probabilities for a sensorimotor norm for a modality given a token

### Get unigram of tokens
"""

# get the unigram counts from bert.eng.uncased.unigrams.csv
file_path = '/content/drive/My Drive/Lancaster/CSVs/bert.eng.uncased.unigrams.csv'

# 1. Load the "clean" version (skips rows that don't match expected format)
unigram_counts_df = pd.read_csv(
    file_path,
    header=None,
    names=["word", "count"],
    delim_whitespace=True,
    on_bad_lines="skip"
)

# 2. Capture the bad lines manually
bad_lines = []
with open(file_path, "r", encoding="utf-8") as f:
    for i, line in enumerate(f, start=1):
        parts = line.strip().split()
        if len(parts) != 2:   # expected exactly 2 fields: word + count
            bad_lines.append((i, line.strip()))

# Save bad lines to a separate CSV for inspection
bad_lines_df = pd.DataFrame(bad_lines, columns=["line_number", "content"])
bad_lines_df.to_csv("bad_lines.csv", index=False)

print("✅ Clean data loaded:", unigram_counts_df.shape)
print("⚠️ Bad lines saved to bad_lines.csv:", len(bad_lines))

# tokenize words in unigram_counts_df in batches
from tqdm import tqdm
token_counts = pd.DataFrame({"tokens": [], "counts": []})
def tokenize_in_batches(df, batch_size=1000):
    tokenized_words = []
    for start in range(0, len(df), batch_size):
        tqdm.write(f"Tokenizing batch {start} to {start+batch_size}")
        batch = df["word"].iloc[start:start+batch_size].tolist()
        tokens = tokenizer(batch, add_special_tokens=False)["input_ids"]
        tokenized_words.extend(tokens)
    return tokenized_words

# run batching
tokenized = tokenize_in_batches(unigram_counts_df, batch_size=1000)

# delete first row in unigram_counts_df (has the word unigram : count)
unigram_counts_df = unigram_counts_df.iloc[1:]
# delete first item in tokenized
tokenized = tokenized[1:]

# 1) Ensure counts are numeric ints
counts = pd.to_numeric(unigram_counts_df["count"], errors="coerce").fillna(0).to_numpy(np.int64)

# 2) Build lens of token lists
lens = np.fromiter((len(t) for t in tokenized), dtype=np.int64, count=len(tokenized))

# 3) Flatten tokens into one int64 array
total = int(lens.sum())
if total == 0:
    flat_tokens = np.array([], dtype=np.int64)
else:
    flat_tokens = np.empty(total, dtype=np.int64)
    pos = 0
    for t in tokenized:
        n = len(t)
        if n:
            flat_tokens[pos:pos+n] = np.asarray(t, dtype=np.int64)
            pos += n

# 4) Repeat counts to align with flattened tokens and cast to float64 for weights
rep_counts = np.repeat(counts, lens).astype(np.float64)

# Sanity check
assert flat_tokens.shape[0] == rep_counts.shape[0]

# 5) Aggregate with np.unique + np.bincount
uniq_tokens, inv = np.unique(flat_tokens, return_inverse=True)
totals = np.bincount(inv, weights=rep_counts)

token_counts = pd.DataFrame({"token": uniq_tokens, "count": totals})

# get total count
total_count = token_counts["count"].sum()
# normalize counts
token_counts["count"] = token_counts["count"] / total_count

token_counts.to_csv("/content/drive/My Drive/Lancaster/token_counts.csv")

"""### Maximized sensorimotor tokens per modality"""

token_counts = pd.read_csv('/content/drive/My Drive/Lancaster/token_counts.csv')

english_words = pd.read_csv(
    '/content/drive/My Drive/Lancaster/english_words.txt',
    header=None,
    names=["word"],
    engine="python"
  )["word"].tolist()
# specifically for affixes for now (tokens with ##)

path = '/content/drive/My Drive/Lancaster/all_tokens_sensorimotor.pt'

# add_safe_globals([pd.DataFrame])          # allow-list DataFrame
all_tokens_sensorimotor_df = torch.load(path, weights_only=False)
device = "cuda" if torch.cuda.is_available() else "cpu"

# df["sensorimotor"] is a column of tensors; stack them into one big matrix
sm_matrix = torch.stack(all_tokens_sensorimotor_df["sensorimotor"].tolist()).to(device)   # (V, D)
token_ids = all_tokens_sensorimotor_df["token_id"].tolist() if "token_id" in all_tokens_sensorimotor_df.columns else list(range(len(all_tokens_sensorimotor_df)))


# FILTERING IF NEEDED
# filter tokens that are in english_words

keep_idx = []
keep_token_ids = []
for idx, tid in enumerate(token_ids):
  if idx % 100 == 0:
    print(idx/len(token_ids))
  tok = tokenizer.convert_ids_to_tokens(tid)
  if tok not in english_words:
      keep_idx.append(idx)
      keep_token_ids.append(tid)

sm_matrix = sm_matrix[keep_idx]
token_ids = keep_token_ids

# save all modality tokens
with open('/content/drive/My Drive/Lancaster/sm_matrix_phonesthemes.pkl', 'wb') as f:
  pickle.dump(sm_matrix, f)
# save all modality tokens
with open('/content/drive/My Drive/Lancaster/phonesthemes_token_ids.pkl', 'wb') as f:
  pickle.dump(token_ids, f)

# load from pickle
with open('/content/drive/My Drive/Lancaster/sm_matrix_phonesthemes.pkl', 'rb') as f:
  sm_matrix = pickle.load(f)
with open('/content/drive/My Drive/Lancaster/phonesthemes_token_ids.pkl', 'rb') as f:
  token_ids = pickle.load(f)

def get_max_probabilty_words_by_modality(token_ids, sm_matrix, modality_idx, k, tau=0.7):

  # Filter by tau, target modality > tau, rest below
  keep_idx = []
  keep_token_ids = []
  num_found = 0
  for idx, entry in enumerate(sm_matrix):
    target_modality_prob = entry[modality_idx]
    # print(entry[modality_idx])
    # print(tokenizer.convert_ids_to_tokens(token_ids[idx]))
    keep = True
    for mod_idx_single in range(0,11):
      if mod_idx_single == modality_idx:
        continue
      elif float(entry[mod_idx_single]) >= target_modality_prob:
        # print("high mod: ", mod_idx_single, float(torch.sigmoid(entry[mod_idx_single])))
        keep = False
    if keep:
      keep_idx.append(idx)
      num_found+=1
      keep_token_ids.append(token_ids[idx])

  sm_matrix = sm_matrix[keep_idx]
  # prob_modality_given_token = prob_modality_given_token[keep_idx]
  token_ids = keep_token_ids
  ids = token_ids

  # # Get p(m_i|t) for all tokens t
  # raw_vals = sm_matrix[:, modality_idx].to(dtype=torch.float32)
  # prob_modality_given_token = torch.sigmoid(raw_vals)
  # # make safe for taking log
  # eps = torch.finfo(prob_modality_given_token.dtype).tiny
  # prob_modality_given_token = torch.where(
  #     torch.isfinite(prob_modality_given_token) & (prob_modality_given_token > 0),
  #     prob_modality_given_token,
  #     torch.full_like(prob_modality_given_token, eps)
  # )

  # # log
  # log_prob_modality_given_token = torch.log(prob_modality_given_token)


  # # # Get p(t) for all these tokens
  # count_map = dict(zip(token_counts["token"].to_numpy(), token_counts["count"].to_numpy()))
  # prob_token_in_bert = torch.as_tensor(
  #     [count_map.get(t, 0.0) for t in token_ids],
  #     dtype=torch.float32,
  #     device=device
  # )
  # prob_token_in_bert = torch.clamp(prob_token_in_bert, min=eps)  # safe for logs


  # # take log
  # final_prob = log_prob_modality_given_token + torch.log(prob_token_in_bert)

  # nearest_dists, nearest_pos = final_prob.topk(k=min(k, final_prob.numel()), dim=0, largest=True)
  # idx_list = nearest_pos.reshape(-1).tolist()
  # ids = [token_ids[i] for i in idx_list]
  tokens = tokenizer.convert_ids_to_tokens(ids)
  # distances = nearest_dists.squeeze(0).tolist()

  return tokens, num_found

k = 400
taus = [0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4]
modalities = ['Auditory', 'Gustatory',	'Haptic',
                        'Interoceptive',	'Olfactory',	'Visual',
                        'Foot_leg' ,	'Hand_arm',	'Head',
                        'Mouth', 'Torso']

all_modalities_tokens = []

for idx, modality in enumerate(modalities):
  print(modality, 'tau:',taus[idx])

  max_prob_words, num_found = get_max_probabilty_words_by_modality(token_ids, sm_matrix, idx,k,taus[idx])
  print(num_found, max_prob_words, )
  all_modalities_tokens.append(max_prob_words)

# save all modality tokens
with open('/content/drive/My Drive/Lancaster/all_modalities_tokens.pkl', 'wb') as f:
  pickle.dump(all_modalities_tokens, f)

"""### Tokenize all words in dictionary and list of words that contain each token"""

# load all_modalities_tokens
all_modalities_tokens = []
with open('/content/drive/My Drive/Lancaster/all_modalities_tokens.pkl', 'rb') as f:
  all_modalities_tokens = pickle.load(f)
print(all_modalities_tokens)

# Call the function above with top 5 tokens from all modalities
# all_modalities_tokens = [Auditory, Gustatory,	Haptic,
#                         Interoceptive,	Olfactory,	Visual,
#                         Foot_leg ,	Hand_arm,	Head,
#                         Mouth, Torso]
modalities = ['Auditory', 'Gustatory','Haptic',
                        'Interoceptive',	'Olfactory',	'Visual',
                        'Foot_leg' ,	'Hand_arm',	'Head',
                        'Mouth', 'Torso']

# Get words that contain a token
english_words = pd.read_csv(
    '/content/drive/My Drive/Lancaster/english_words.txt',
    header=None,
    names=["word"],
    engine="python"
)["word"].tolist()

# build tokenized list of words
tokenized_words = []
words_for_tokens = {}
for i,word in enumerate(english_words):
  if i % 10000 == 0:
    print(i/len(english_words))

  if(type(word) != type('str')):
    continue
  max_length = 20
  token_dict = tokenizer(word, return_tensors='pt', padding=True, truncation=True, max_length=max_length)
  # Select the first sequence (batch dimension 0) and convert to list
  input_ids = token_dict['input_ids'][0].tolist()

  tokens = tokenizer.convert_ids_to_tokens(input_ids)
  for token in tokens:
    if token not in words_for_tokens.keys():
      words_for_tokens[token] = []
    words_for_tokens[token].append(word)
  tokenized_words.append(tokens)

# save words for tokens
with open('/content/drive/My Drive/Lancaster/words_for_tokens.pkl', 'wb') as f:
  pickle.dump(words_for_tokens, f)
print(len(tokenized_words))

words_for_tokens['singing']

"""## Filter tokens for each modality based on how many words that contain them are also > tau in the modality"""

# load words_for_tokens
with open('/content/drive/My Drive/Lancaster/words_for_tokens.pkl', 'rb') as f:
  words_for_tokens = pickle.load(f)

def n_words_by_modality(n, words, modality_idx, p_value, bert_model, tokenizer, proj_model):
  device = "cuda" if torch.cuda.is_available() else "cpu"


  filtered_words = []
  all_preds = []

  bert_model.to(device)
  bert_model.eval()

  proj_model.to(device)
  proj_model.eval()

  print("processing", len(words), "words")

  i = 0
  for word in words:
    token = tokenizer(word, return_tensors='pt', padding=True, truncation=True, max_length=30)
    token.to(device)
    input_ids = token['input_ids']
    attention_mask = token['attention_mask']

    with torch.no_grad():
      outputs = bert_model(input_ids=input_ids,
                      attention_mask=attention_mask,
                                output_hidden_states=True)
      cls_out = outputs.hidden_states[-1][:, 0, :].to(device)

      lancaster_pred = proj_model(cls_out)
      lancaster_pred = lancaster_pred.detach().cpu().numpy()[0]
      all_preds.append(lancaster_pred)
      if(lancaster_pred[modality_idx] > p_value):
        # print(lancaster_pred)
        filtered_words.append(word)
        i+=1
        if i == n:
          break
  return filtered_words

import heapq

modalities = ['Auditory', 'Gustatory','Haptic',
                        'Interoceptive',	'Olfactory',	'Visual',
                        'Foot_leg' ,	'Hand_arm',	'Head',
                        'Mouth', 'Torso']

# Get words that contain a token
english_words = pd.read_csv(
    '/content/drive/My Drive/Lancaster/english_words.txt',
    header=None,
    names=["word"],
    engine="python"
)["word"].tolist()


# load /content/drive/My Drive/Lancaster/filtered_tokens_for_modality.pkl'

with open('/content/drive/My Drive/Lancaster/filtered_tokens_for_modality.pkl', 'rb') as f:
  filtered_tokens_for_modality = pickle.load(f)

with open('/content/drive/My Drive/Lancaster/filtered_words_for_modality.pkl', 'rb') as f:
  filtered_words_for_modality = pickle.load(f)

for i, tokens_for_modality in enumerate(all_modalities_tokens):
    print(modalities[i])
    if i<9:
      continue
    # Collect (score, token, words_list) triplets for all tokens
    scored = []
    total = len(tokens_for_modality)

    filtered_tokens = []
    filtered_words = []
    for j, token in enumerate(tokens_for_modality):
        if j % 1 == 0 and total > 0:
            print((j / total) * 100)
        if token not in words_for_tokens:
            continue

        words = words_for_tokens[token]
        filtered_words_cur = n_words_by_modality(5,
            words, i, 0.5, bert_model, tokenizer, neural_model
        )

        score = len(filtered_words_cur)  # number of words over tau for this token

        # only keep the tokens with >= 5 words being high in sensorimotor too
        if score >= 5:
            filtered_tokens.append(token)
            filtered_words.append(filtered_words_cur[0:5])

    print(filtered_tokens)
    print(len(filtered_tokens))
    filtered_tokens_for_modality[modalities[i]] = filtered_tokens
    filtered_words_for_modality[modalities[i]] = filtered_words

    # save cur progress of filtered_tokens_for_modality, filtered_words_for_modality
    with open('/content/drive/My Drive/Lancaster/filtered_tokens_for_modality_v2.pkl', 'wb') as f:
      pickle.dump(filtered_tokens_for_modality, f)
    with open('/content/drive/My Drive/Lancaster/filtered_words_for_modality_v2.pkl', 'wb') as f:
      pickle.dump(filtered_words_for_modality, f)

from google.colab import drive
drive.mount('/content/drive')

filtered_tokens_for_modality = {}
import pickle
# load '/content/drive/My Drive/Lancaster/filtered_tokens_for_modality.pkl'
with open('/content/drive/My Drive/Lancaster/filtered_words_for_modality.pkl', 'rb') as f:
  filtered_tokens_for_modality = pickle.load(f)

print(filtered_tokens_for_modality)

for word in [ '##ing', '##ed',  '##ly',  '##er',  've', '##es', '##on', '##an', '##us', '##al', '##in', '##en']:
  token = tokenizer(word, return_tensors='pt', padding=True, truncation=True, max_length=30)
  token.to(device)
  input_ids = token['input_ids']
  attention_mask = token['attention_mask']

  with torch.no_grad():
    outputs = bert_model(input_ids=input_ids,
                    attention_mask=attention_mask,
                              output_hidden_states=True)
    cls_out = outputs.hidden_states[-1][:, 0, :].to(device)

    lancaster_pred = neural_model(cls_out)
    lancaster_pred = lancaster_pred.detach().cpu().numpy()[0]
    print(word)
    print(lancaster_pred)

"""## Retreiving word piece from CLS token"""

import torch, re

def nearest_wordpieces(z,
                       bert_model,
                       tokenizer,
                       k: int = 20,
                       cosine: bool = True):

    # 1️⃣  Make z shape (1, D)
    if z.dim() == 1:
        z = z.unsqueeze(0)

    # 2️⃣  Put z on same device / dtype as BERT embeddings
    W = bert_model.get_input_embeddings().weight            # (V, D)
    z = z.to(W.device).to(W.dtype)

    # 3️⃣  Optional cosine normalisation
    if cosine:
        z_norm = z.norm(dim=-1, keepdim=True).clamp(min=1e-8)
        z = z / z_norm
        Wn = W / W.norm(dim=-1, keepdim=True).clamp(min=1e-8)
    else:
        Wn = W

    # 4️⃣  Similarity & top-k
    with torch.no_grad():
        sim  = torch.matmul(z, Wn.T).squeeze(0)             # (V,)
        vals, idx = torch.topk(sim, k * 4)                  # oversample

    toks = tokenizer.convert_ids_to_tokens(idx.tolist())

    # 5️⃣  Filter unwanted word-pieces (optional)
    keep = [
        (t, v.item())
        for t, v in zip(toks, vals)
        if t not in tokenizer.all_special_tokens          # [CLS], [PAD] …
        and not t.startswith("[unused")
        and re.fullmatch(r"[A-Za-z]+", t)                 # only alphabetic
    ][:k]

    return keep            # list of (token, score) pairs

import torch
from transformers import BertTokenizerFast, BertForMaskedLM, BertModel
tokenizer_bert_fast  = BertTokenizerFast.from_pretrained("bert-base-uncased")
mlm_model_bert  = BertForMaskedLM.from_pretrained("bert-base-uncased").eval()
plain_bert = mlm_model_bert.bert                # same parameters, no MLM head

# 1NEAREST WORD‑PIECES VIA THE MLM DECODER (layer 12 → MLM head)
def nearest_with_mlm_head(
        h: torch.Tensor,        # (D,) or (1, D)
        mlm_model: BertForMaskedLM = mlm_model_bert,      # model with the MLM head
        tokenizer: BertTokenizerFast = tokenizer_bert_fast,
        k: int = 4
):
    if h.dim() == 1:
      h = h.unsqueeze(0)
    logits = mlm_model.cls(h)                # (1, V)
    probs  = logits.softmax(-1).squeeze(0)
    vals, idx = probs.topk(k)
    toks = tokenizer.convert_ids_to_tokens(idx.tolist())
    return list(zip(toks, vals.tolist()))

from transformers import BertTokenizerFast, BertModel
import torch, numpy as np
device = "cuda" if torch.cuda.is_available() else "cpu"

tok      = BertTokenizerFast.from_pretrained("bert-base-uncased")
bert     = BertModel.from_pretrained("bert-base-uncased").to(device).eval()
HIDDEN   = bert.config.hidden_size      # 768
VOCAB_SZ = bert.config.vocab_size       # 30522

from tqdm import tqdm

def cls_for_token_id(tid: int) -> torch.Tensor:        # (768,)
    text = tok.convert_ids_to_tokens(tid)
    ids  = torch.tensor([[tok.cls_token_id, tid, tok.sep_token_id]],
                        device=device)
    with torch.no_grad():
        h = bert(ids, output_hidden_states=True).hidden_states[-1][0,0]
    return h

# Pre‑compute CLS for every vocab ID (takes ~20 s on CPU, 2 s on GPU)
cls_table = torch.empty(VOCAB_SZ, HIDDEN, device=device)
for tid in tqdm(range(VOCAB_SZ)):
    cls_table[tid] = cls_for_token_id(tid)

# Unit‑norm for cosine similarity
cls_table = torch.nn.functional.normalize(cls_table, dim=1)

def word_from_cls(query_vec, top_k=5):
    """query_vec: (768,) tensor on same device"""
    q = torch.nn.functional.normalize(query_vec, dim=-1).unsqueeze(0)  # (1,768)
    sim = torch.matmul(q, cls_table.T).squeeze(0)     # (V,)
    vals, idx = sim.topk(top_k)
    return [(tok.convert_ids_to_tokens(i.item()), vals[j].item())
            for j, i in enumerate(idx)]

# example
word     = data['word'][1921]
tid      = tok.convert_tokens_to_ids(word)
query_cls = cls_table[tid]               # pretend we only have the CLS

print(word_from_cls(query_cls, top_k=8))
print(word)

"""## Running inverse model"""

# Cosine sim bw words

import torch.nn.functional as F

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Make sure both models are on the same device
bert_model.to(device).eval()
neural_model.to(device).eval()

for word in tokens:
  # Tokenize, then move every tensor in the dict to that device
  tokens_acc = tokenizer(
      word,
      return_tensors='pt',
      padding=True,
      truncation=True,
      max_length=20
  )
  tokens_acc = {k: v.to(device) for k, v in tokens_acc.items()}

  # Forward pass
  with torch.no_grad():  # remove this if you need gradients
      outputs = bert_model(**tokens_acc)
      cls_representations = outputs.last_hidden_state[:, 0, :]  # [CLS]

  out = neural_model(cls_representations)
  print(out)

  p1 = torch.tensor(out).to(device)
  p2 = torch.tensor(data['sensorimotor'][14356]).to(device)

  # cosine sim between out and data['sensorimotor'][14356]
  cos = criterion(p1, p2)
  print("mse :", cos)
print("og      :", data['sensorimotor'][14356])

tokenizer.convert_ids_to_tokens(2193)

# Testing Inverted model sensorimotor -> embedding
em  = neural_model(torch.as_tensor(data['sensorimotor'][2124],
                                         dtype=torch.float32))          # (11,) or (768,)

emb_true = torch.as_tensor(data['embedding'][2124], dtype=em.dtype)    # (11,) or (768,)
import torch.nn.functional as F

cos = F.cosine_similarity(em, emb_true, dim=0)   # scalar in [-1, 1]
print("cosine :", cos.item())

# check the norms
print("‖em‖      :", em.norm().item())
print("‖emb_true‖:", emb_true.norm().item())
print("dot(em,emb):", torch.dot(em, emb_true).item())

"""## Evaluate"""

def evaluate(model, test_loader):
  #Evaluate
  loss_per_dimension = {'Auditory':0, 'Gustatory': 0,	'Haptic': 0,
                        'Interoceptive': 0,	'Olfactory': 0,	'Visual': 0,
                        'Foot_leg' : 0,	'Hand_arm':0,	'Head': 0,
                        'Mouth':	0, 'Torso': 0}

  losses = [0,0,0,0,0,0,0,0,0,0,0]
  total_loss = 0.0

  predictions = pd.DataFrame(columns=['input', 'prediction', 'target', 'mse', 'mse_aud', 'mse_gus', 'mse_hap', 'mse_int', 'mse_olf', 'mse_vis', 'mse_foot', 'mse_hand', 'mse_head', 'mse_mouth', 'mse_torso'])
  with torch.no_grad():
      for data in test_loader:  # test_loader is your DataLoader for test data
          inputs, targets = data
          outputs = model(inputs)
          # iterating through batch
          for input, output,target in zip(inputs, outputs,targets):
            input_list = input.tolist()
            output_list = output.tolist()
            target_list = target.tolist()
            pred_list = [input_list, output_list, target_list,criterion(output,target)]
            for dim_id in range(0,11):
              loss_dim = criterion(output[dim_id],target[dim_id])
              losses[dim_id] += loss_dim
              pred_list.append(loss_dim)
            # Use loc to append a new row
            predictions.loc[len(predictions)] = pred_list

          loss = criterion(outputs, targets)
          total_loss += loss.item()

  for i, key in enumerate(loss_per_dimension.keys()):
      losses[i] /= (len(test_loader) * 32)
      losses[i] = losses[i].item()
      loss_per_dimension[key] = losses[i]

  print(loss_per_dimension)
  print('Average test loss:', total_loss / len(test_loader))

  return (total_loss / len(test_loader), loss_per_dimension, predictions)

## NN
test_dataset = VectorDataset(X_dev, Y_dev)
test_loader =  DataLoader(test_dataset, batch_size=32, shuffle=True)

avg_loss_neural, loss_per_dimension_neural,predictions_neural = evaluate(neural_model, test_loader)

#  KNN
# X_temp = X_dev[0:int(len(X_dev)/10)]
# Y_temp = Y_dev[0:int(len(Y_dev)/10)]
# dev_dataset = VectorDataset(X_temp, Y_temp)
# dev_loader =  DataLoader(dev_dataset, batch_size=32, shuffle=True)

# avg_loss_knn, loss_per_dimension_knn, predictions_knn = evaluate(model_knn, dev_loader)

# # Average Model
# avg_loss_avg, loss_per_dimension_avg, predictions_avg = evaluate(avg_model,test_loader)



print(data_type)

avg_loss_avg, loss_per_dimension_avg, predictions_avg = evaluate(avg_model,test_loader)

print(avg_loss_avg)

"""## Save Results"""

# Create a dictionary to store all the data
NN_data_to_save = {
    'avg_loss_neural': avg_loss_neural,
    'loss_per_dimension_neural': loss_per_dimension_neural,
    'predictions_neural': predictions_neural
}

# Save to a file using pickle
filename = "/content/drive/My Drive/Lancaster/NN_results_" + data_type + ".pkl"
with open(filename, 'wb') as file:
    pickle.dump(NN_data_to_save, file)

print(avg_loss_neural)

"""## Load Results"""

# Load the data from the file
avg_losses = {"word2vec_intersection" : 0, "glove_intersection": 0, "bert_intersection": 0, 'clip': 0, 'blip': 0, 'flan_t5': 0}
losses_per_dimension = {"word2vec_intersection" : {}, "glove_intersection": {}, "bert_intersection": {}, 'clip': {}, 'blip': {}, 'flan_t5': {}}
predictions =  {"word2vec_intersection" : pd.DataFrame({}), "glove_intersection": pd.DataFrame({}), "bert_intersection": pd.DataFrame({}), 'clip': pd.DataFrame({}), 'blip': pd.DataFrame({}), 'flan_t5': pd.DataFrame({})}
for data_type in ["word2vec_intersection", "glove_intersection", "bert_intersection"]:
  filename = "/content/drive/My Drive/Lancaster/NN_results_" + data_type + ".pkl"
  with open(filename, 'rb') as file:
      loaded_data = pickle.load(file)

  # Access the data
  avg_losses[data_type] = loaded_data['total_loss_neural'] if 'total_loss_neural' in loaded_data else loaded_data['avg_loss_neural']
  losses_per_dimension[data_type] = loaded_data['loss_per_dimension_neural']
  predictions[data_type] = pd.DataFrame(loaded_data['predictions_neural'])

predictions_neural = predictions["word2vec_intersection"]

"""## Visualization"""

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from scipy import stats

# Updated data types list
data_types = ["word2vec_intersection", "glove_intersection", "bert_intersection", "clip", "blip", "flan_t5"]

# Friendly display names mapping
display_names = {
    "word2vec_intersection": "Word2Vec",
    "glove_intersection": "GloVe",
    "bert_intersection": "BERT",
    "clip": "CLIP",
    "blip": "BLIP",
    "flan_t5": "FLAN-T5"
}

# Color mapping for consistency
colors = {
    "Word2Vec": "blue",
    "GloVe": "green",
    "BERT": "red",
    "CLIP": "purple",
    "BLIP": "orange",
    "FLAN-T5": "teal"
}

# 1. Prepare data for Seaborn (long-format)
# For loss per dimension
dimension_data = []

# Extract the keys (dimensions)
dimensions = list(losses_per_dimension["word2vec_intersection"].keys())

for dimension in dimensions:
    for data_type in data_types:
        # convert auditory, gustatory and everything to abbrevation if nessazity for this datatype
        if data_type != 'word2vec_intersection':
          if dimension == 'Auditory':
            dimension = 'aud'
          elif dimension == 'Gustatory':
            dimension = 'gus'
          elif dimension == 'Haptic':
            dimension = 'hap'
          elif dimension == 'Interoceptive':
            dimension = 'int'
          elif dimension == 'Olfactory':
            dimension = 'olf'
          elif dimension == 'Visual':
            dimension = 'vis'
          elif dimension == 'Foot_leg':
            dimension = 'foot'
          elif dimension == 'Hand_arm':
            dimension = 'hand'
          elif dimension == 'Head':
            dimension = 'head'
          elif dimension == 'Mouth':
            dimension = 'mouth'
          elif dimension == 'Torso':
            dimension = 'torso'

        dimension_data.append({
            'Dimension': dimension,
            'Loss': losses_per_dimension[data_type][dimension],
            'Embedding': display_names[data_type]
        })

dimension_df = pd.DataFrame(dimension_data)

# For average losses
avg_loss_data = []
for data_type in data_types:
    avg_loss_data.append({
        'Embedding': display_names[data_type],
        'Average Loss': avg_losses[data_type]
    })
avg_loss_df = pd.DataFrame(avg_loss_data)

# 2. Set up the plots with Seaborn
plt.figure(figsize=(18, 14))



print(predictions_neural.iloc[0])

"""##Result Analysis"""

# Getting word2vec original words
file_path = "/content/drive/My Drive/Lancaster/word_vectors_model.bin"


word_vectors = KeyedVectors.load(file_path)

def set_data(embedding_type):
  data_location = ""
  if embedding_type == 'word2vec':
    data_location = '/content/drive/My Drive/Lancaster/data.pt'
  elif embedding_type == 'glove':
    data_location = '/content/drive/My Drive/Lancaster/data_glove.pt'
  elif embedding_type == 'bert':
    data_location = '/content/drive/My Drive/Lancaster/cls_tokens.pt'
  elif embedding_type == 'word2vec_intersection':
    data_location = "/content/drive/My Drive/Lancaster/intersect_word2vec.pt"
  elif embedding_type == 'glove_intersection':
    data_location = "/content/drive/My Drive/Lancaster/intersect_glove.pt"
  elif embedding_type == 'bert_intersection':
    data_location = "/content/drive/My Drive/Lancaster/intersect_cls_tokens.pt"

  return torch.load(data_location)
data = set_data("word2vec_intersection")

data.reset_index(drop=True, inplace=True)

print(data['word'][122])
print(data.iloc[122]['word'])

predictions_neural['target']

# Function to find the word by vector value
def find_word_by_vector(target_vector):
    target_vector = torch.tensor(target_vector)

    # Find index in data where data['embedding'] = target vector
    embeddings = data['embedding']


    embeddings = embeddings.apply(lambda x: pd.eval(x) if isinstance(x, str) else x)

    # Ensure all elements in the embeddings are numeric and convert to a numpy array
    embeddings = np.vstack(embeddings.values)

    # Convert embeddings to a PyTorch tensor
    embeddings = torch.tensor(embeddings, dtype=torch.float32)


    matching_indices = torch.all(embeddings == target_vector.unsqueeze(0), dim=1).nonzero(as_tuple=True)[0]
    # Check if any matching indices are found
    if matching_indices.numel() == 0:
      print("No matching vector found.")
      return None
    else:
      for index in matching_indices:
        print(f"Matching vector found at index: {index.item()}")
        return data['word'][index.item()]

# Filter predictions where the 2nd element (gustatory) in 'target' is between 4.5 and 1
filtered_predictions = predictions_neural[predictions_neural['target'].apply(lambda x: 0 <= x[1] <= 0.1)]

mse_ascending_predictions = filtered_predictions.sort_values(by='mse_gus', ascending=False)


target_predictions = pd.DataFrame(columns=['word', 'prediction', 'target', 'mse_gus'])

# find best 100 matches words
for i in range(20):
  prediction = mse_ascending_predictions.iloc[i]
  word = find_word_by_vector(prediction['input'])
  pred_list = [word, prediction['prediction'][1] * 5, prediction['target'][1] * 5, prediction['mse_gus']]
  target_predictions.loc[len(target_predictions)] = pred_list


# Set Pandas display options to avoid truncation
pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
pd.set_option('display.max_colwidth', None)

from IPython.display import display

display(target_predictions)

# print(target_predictions)

# Function to search for specific words in the DataFrame
def search_words(df, words):
    return df.loc[df['word'].isin(words)]


# Example search for specific words
words_to_search = ['blue', 'bed']
search_results = search_words(target_predictions, words_to_search)

# Set Pandas display options to avoid truncation
pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
pd.set_option('display.max_colwidth', None)

print("\nSearch Results for Specific Words:")
print(target_predictions['word'])

pd.set_option('display.max_colwidth', None)
{'Auditory':0, 'Gustatory': 0,	'Haptic': 0,
                        'Interoceptive': 0,	'Olfactory': 0,	'Visual': 0,
                        'Foot_leg' : 0,	'Hand_arm':0,	'Head': 0,
                        'Mouth':	0, 'Torso': 0}
print(worst_predictions.iloc[0])

# To predict

def predict(input_word):
  inputs = [word_vectors[input_word]]
  output = neural_model(inputs)[0]
  return output

"""## Plot losses across dimensions"""

# loss_per_dimension = loss_per_dimension_knn
loss_per_dimension = loss_per_dimension_neural

# Extract the keys and values from the dictionary
dimensions = list(loss_per_dimension.keys())
loss_values = list(loss_per_dimension.values())

# Create a bar chart
plt.figure(figsize=(10, 6))
plt.bar(dimensions, loss_values, color='blue')
plt.xlabel('Dimensions')
plt.ylabel('Loss')
plt.title('Loss per Dimension')
plt.xticks(rotation=45)  # Rotate x-axis labels for better readability
plt.tight_layout()

# Show the plot
plt.show()

"""## KNN cosine similarity setter"""

X_temp = X_dev[0:int(len(X_dev)/10)]
# Find cosine similarity of all dev items with each train item
cosine_sim = np.zeros((len(X_temp),len(X_train)))
print(cosine_sim.shape)
for i, temp_item in enumerate(X_temp):
  if i % 5 == 0:
    print(str((i/(len(X_temp)))*100) + "% done")
  for j, train_item in enumerate(X_train):
    sim_score = cosine_similarity([temp_item], [train_item])
    # sim_score is a 2D array; extract a single value to assign
    cosine_sim[i][j] = sim_score[0][0]

file_path = ''
if data_type == 'word2vec':
  file_path = '/content/drive/My Drive/Lancaster/cosine_similarity.npy'
elif data_type == 'glove':
  file_path = '/content/drive/My Drive/Lancaster/cosine_similarity_glove.npy'
elif data_type == 'bert':
  file_path = '/content/drive/My Drive/Lancaster/cosine_similarity_bert.npy'
elif data_type == 'word2vec_intersection':
  file_path = "/content/drive/My Drive/Lancaster/cosine_similarity_intersect_word2vec.pt"
elif data_type == 'glove_intersection':
  file_path = "/content/drive/My Drive/Lancaster/cosine_similarity_intersect_glove.pt"
elif data_type == 'bert_intersection':
  file_path = "/content/drive/My Drive/Lancaster/cosine_similarity_intersect_cls_tokens.pt"
# Save the cosine_sim matrix to the specified file path
np.save(file_path, cosine_sim)

"""##Reverse Experiment cosine"""

# Cosine sim for reverse experiment

# get all word2vec
file_path = "/content/drive/My Drive/Lancaster/word_vectors_model.bin"

word_vectors = KeyedVectors.load(file_path)

vocab_size = len(word_vectors.index_to_key)
vector_size = word_vectors.vector_size

# Initialize a PyTorch embedding layer
pytorch_embedding = torch.nn.Embedding(vocab_size, vector_size)

# Fill the embedding layer with the gensim weights
for i, word in enumerate(word_vectors.index_to_key):
    pytorch_embedding.weight.data[i] = torch.tensor(word_vectors[word])

print(word_vectors)

cosine_sim = np.zeros((len(word_vectors)))

for i, word in enumerate(word_vectors.index_to_key):
  vector1 = torch.tensor(word_vectors[word])
  vector2 = torch.tensor([])
  sim_score = cosine_similarity([vector1], [vector2])
  cosine_sim[i] = sim_score[0][0]

res = []
temp = sorted(cosine_sim)[-5:]
for ele in temp:
  # encapsulating elements with index using index()
  index = 0
  for id, item in enumerate(cosine_sim):
      if np.array_equal(item,ele):
        index = id
        break
  res.append((index, ele))

words = word_vectors.index_to_key

for entry in res:
  train_idx, sim = entry
  word = words[train_idx]
  print(word)

"""## Creating word2vec dataset"""

data = pd.read_csv('/content/drive/My Drive/Lancaster/lancaster-ensorimotor-norms.csv')

file_path = "/content/drive/My Drive/Lancaster/word_vectors_model.bin"

# word_vectors = api.load("word2vec-google-news-300")

# word_vectors.save(file_path)

word_vectors = KeyedVectors.load(file_path)

print(word_vectors)
def convert_gensim_to_pytorch(gensim_model):
    vocab_size = len(gensim_model.index_to_key)
    vector_size = gensim_model.vector_size

    # Initialize a PyTorch embedding layer
    embedding = torch.nn.Embedding(vocab_size, vector_size)

    # Fill the embedding layer with the gensim weights
    for i, word in enumerate(gensim_model.index_to_key):
        embedding.weight.data[i] = torch.tensor(gensim_model[word])

    return embedding

pytorch_embedding = convert_gensim_to_pytorch(word_vectors)


phrases = data['Word']

data['word'] = np.empty(len(phrases), dtype=str)
data['embedding'] = np.empty(len(phrases), dtype=object)
data['sensorimotor'] = np.empty(len(phrases), dtype=object)


data_copy = {}
df = pd.DataFrame(data_copy)

for idx,phrase in phrases.items():
  try:
        # split phrase into words
        words = phrase.split()
        average_embedding = torch.zeros(pytorch_embedding.embedding_dim)
        valid_word_count = 0
        for word in words:
          word_index = word_vectors.key_to_index[word.lower()]  # Get the index of the word
          word_index_tensor = torch.tensor(word_index)  # Convert the index to a PyTorch tensor
          word_embedding = pytorch_embedding(word_index_tensor)  # Get the word embedding
          average_embedding += word_embedding
          valid_word_count += 1

        if valid_word_count > 0:
          average_embedding = average_embedding / valid_word_count
        else:
          average_embedding = None  # Handle case with no valid words

        # construct vector for sensorimotor
        sensorimotor = []
        all_values = data.iloc[idx]
        mean_values = (all_values.iloc[1:12])/5 #setting them between 0-1
        for col,value in mean_values.items():
          sensorimotor.append(value)
        # data_copy = data.copy()  # Create a copy of the DataFrame
        # data_copy['sensorimotor'][idx] = sensorimotor  # Modify the copy
        # data.loc[idx] = data_copy.loc[idx]

        new_row = {'word': phrase, 'sensorimotor': sensorimotor,'embedding': average_embedding.detach().numpy()}
        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)

  except KeyError:
        # Handle the case where the word is not in the word_vectors vocabulary
        # You can choose to skip it or use a default embedding in such cases
        print(f"Word '{phrase}' not found in the vocabulary.")


data = df

data_location = '/content/drive/My Drive/Lancaster/data.pt'

torch.save(data, data_location)

print(word_vectors["apple"])

"""## Creating CLIP Dataset"""

from transformers import CLIPTokenizer, CLIPTextModel

# Load CLIP model and tokenizer
device = "cuda" if torch.cuda.is_available() else "cpu"
clip_model_name = "openai/clip-vit-base-patch32"  # You can choose another CLIP variant
tokenizer = CLIPTokenizer.from_pretrained(clip_model_name)
model = CLIPTextModel.from_pretrained(clip_model_name).to(device)
model.eval()

# Load sensorimotor dataset
data = pd.read_csv('/content/drive/My Drive/Lancaster/CSVs/lancaster-ensorimotor-norms.csv')

# Initialize a new DataFrame
data_copy = {'word': [], 'embedding': [], 'sensorimotor': []}


# Function to get CLIP text embeddings
def get_clip_embedding(phrase):
    tokens = tokenizer(phrase, return_tensors="pt", padding=True, truncation=True).to(device)
    with torch.no_grad():
        outputs = model(**tokens)
        embedding = outputs.last_hidden_state.mean(dim=1).squeeze().cpu()  # Mean pooling
    return embedding


phrases = data['Word']

data['word'] = np.empty(len(phrases), dtype=str)
data['embedding'] = np.empty(len(phrases), dtype=object)
data['sensorimotor'] = np.empty(len(phrases), dtype=object)


data_copy = {'word': [], 'embedding': [], 'sensorimotor': []}

# Loop through phrases and compute embeddings
for idx, phrase in data['Word'].items():
    try:
        # CLIP embedding for the phrase
        clip_embedding = get_clip_embedding(phrase)

        # Normalize sensorimotor values (0-1 range)
        sensorimotor = []
        all_values = data.iloc[idx]
        mean_values = (all_values.iloc[1:12]) / 5
        for col, value in mean_values.items():
            sensorimotor.append(value)

        # Add data to the new structure
        data_copy['word'].append(phrase)
        data_copy['embedding'].append(clip_embedding.numpy())
        data_copy['sensorimotor'].append(sensorimotor)

    except Exception as e:
        print(f"Error processing '{phrase}': {e}")

# Convert to DataFrame
df = pd.DataFrame(data_copy)

# Save the dataset
data_location = '/content/drive/My Drive/Lancaster/clip_data.pt'
torch.save(df, data_location)

print("Dataset saved successfully with CLIP embeddings.")

"""## Creating BPE embedding dataset"""

import pandas as pd
import torch
from transformers import BertTokenizerFast, BertModel

csv_path = "/content/drive/My Drive/Lancaster/CSVs/lancaster-ensorimotor-norms.csv"
df       = pd.read_csv(csv_path)

tok   = BertTokenizerFast.from_pretrained("bert-base-uncased")
bert  = BertModel.from_pretrained("bert-base-uncased")
E     = bert.get_input_embeddings().weight.detach().cpu()

def avg_static_embedding(word: str) -> list:
    pieces = tok.tokenize(word.lower())
    ids    = tok.convert_tokens_to_ids(pieces)
    vec    = E[ids].mean(dim=0)
    return vec.numpy().tolist()

df["embedding"] = df["Word"].apply(avg_static_embedding)


sense_cols = [
    "Auditory.mean", "Gustatory.mean", "Haptic.mean",
    "Interoceptive.mean", "Olfactory.mean", "Visual.mean",
    "Foot_leg.mean", "Hand_arm.mean", "Head.mean",
    "Mouth.mean", "Torso.mean"
]
df["sensorimotor"] = df[sense_cols].to_numpy().tolist()


df_final = df[["Word", "embedding", "sensorimotor"]].rename(columns={"Word": "word"})

print(df_final.head())

torch.save(df_final, "/content/drive/My Drive/Lancaster/bpe_tokens.pt")





"""## Pseudowords (wuggy) predicted sensorimotor and get top for each *modality*"""

pseudoword_df = pd.read_csv('/content/drive/My Drive/Lancaster/CSVs/wuggy_pseudowords_2.csv')
pseudowords = pseudoword_df['pseudoword'].tolist()
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertModel.from_pretrained('bert-base-uncased')

# Tokenizeing all words and convert to IDs, padding/truncating as necessary
max_length = 20
tokens = tokenizer(pseudowords, return_tensors='pt', padding=True, truncation=True, max_length=max_length)

# Convert tokens to a DataLoader for efficient batching
batch_size = 32
dataset = TensorDataset(tokens['input_ids'], tokens['attention_mask'])
dataloader = DataLoader(dataset, batch_size=batch_size)

# Move model to GPU if available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Pre-allocate tensor for [CLS] token representations
cls_tokens = torch.zeros((len(pseudowords), model.config.hidden_size), device=device)

# Process in batches
with torch.no_grad():
    model.eval()
    start_idx = 0
    for batch in dataloader:
        input_ids, attention_mask = [b.to(device) for b in batch]

        outputs = model(input_ids=input_ids, attention_mask=attention_mask)

        # Extract [CLS] tokens and store in pre-allocated tensor
        cls_representations = outputs.last_hidden_state[:, 0, :]
        cls_tokens[start_idx:start_idx+cls_representations.size(0)] = cls_representations

        start_idx += cls_representations.size(0)

words = pseudowords
data_copy = {}
df = pd.DataFrame(data_copy)

for idx,word in enumerate(words):
    word_embedding = cls_tokens[idx] # Get the word embedding

    # construct vector for sensorimotor
    sensorimotor = neural_model.predict(word_embedding.unsqueeze(0))
    print(sensorimotor)
    # data_copy = data.copy()  # Create a copy of the DataFrame
    # data_copy['sensorimotor'][idx] = sensorimotor  # Modify the copy
    # data.loc[idx] = data_copy.loc[idx]
    new_row = {'word': word, 'sensorimotor': sensorimotor,'embedding': word_embedding.cpu().detach().numpy()}
    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)


data = df

# Save
torch.save(data, '/content/drive/My Drive/Lancaster/pseudowords_sensorimotor_projection.pt')

"""### Get maximized pseudowrds per modality


"""

def get_top_pseudowords(modality_idx, k=10):
  pseudowords_sensorimotor_df = torch.load('/content/drive/My Drive/Lancaster/pseudowords_sensorimotor_projection.pt')
  # df["sensorimotor"] is a column of tensors; stack them into one big matrix
  sm_matrix = torch.stack(pseudowords_sensorimotor_df["sensorimotor"].tolist()).to(device)   # (V, D)
  words = pseudowords_sensorimotor_df["word"].tolist()

  raw_vals = sm_matrix[:, modality_idx].to(dtype=torch.float32)
  prob_modality_given_token = torch.sigmoid(raw_vals)

  nearest_dists, nearest_pos = prob_modality_given_token.topk(k=min(k, prob_modality_given_token.numel()), dim=0, largest=True)
  idx_list = nearest_pos.reshape(-1).tolist()

  words_top = [words[i] for i in idx_list]
  distances = nearest_dists.squeeze(0).tolist()

  return words_top, distances

modalities = ['Auditory', 'Gustatory',	'Haptic',
                        'Interoceptive',	'Olfactory',	'Visual',
                        'Foot_leg' ,	'Hand_arm',	'Head',
                        'Mouth', 'Torso']

for i in range(11):
  print(modalities[i])
  print(get_top_pseudowords(i, k=10))

"""## Creating CLS Token Dataset

## BERT Tokenizer
"""

# Initialize tokenizer and model
# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
# model = BertModel.from_pretrained('bert-base-uncased')
tokenizer = RobertaTokenizer.from_pretrained('roberta-base')
model = RobertaModel.from_pretrained('roberta-base')

# Loading data
data = pd.read_csv('/content/drive/My Drive/Lancaster/CSVs/lancaster-ensorimotor-norms.csv')
words = data['Word'].tolist()


# def cls_for_token_id(tid: int) -> torch.Tensor:        # (768,)
#     text = tok.convert_ids_to_tokens(tid)
#     ids  = torch.tensor([[tok.cls_token_id, tid, tok.sep_token_id]],
#                         device=device)
#     with torch.no_grad():
#         h = bert(ids, output_hidden_states=True).hidden_states[-1][0,0]
#     return h


# Tokenizeing all words and convert to IDs, padding/truncating as necessary
max_length = 20
tokens = tokenizer(words, return_tensors='pt', padding=True, truncation=True, max_length=max_length)

# Convert tokens to a DataLoader for efficient batching
batch_size = 32
dataset = TensorDataset(tokens['input_ids'], tokens['attention_mask'])
dataloader = DataLoader(dataset, batch_size=batch_size)

# Move model to GPU if available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Pre-allocate tensor for [CLS] token representations
cls_tokens = torch.zeros((len(words), model.config.hidden_size), device=device)

# Process in batches
with torch.no_grad():
    model.eval()
    start_idx = 0
    for batch in dataloader:
        input_ids, attention_mask = [b.to(device) for b in batch]

        outputs = model(input_ids=input_ids, attention_mask=attention_mask)

        # Extract [CLS] tokens and store in pre-allocated tensor
        cls_representations = outputs.last_hidden_state[:, 0, :]
        cls_tokens[start_idx:start_idx+cls_representations.size(0)] = cls_representations

        start_idx += cls_representations.size(0)

data = pd.read_csv('/content/drive/My Drive/Lancaster/CSVs/lancaster-ensorimotor-norms.csv')

words = data['Word'].tolist()

data['embedding'] = np.empty(len(words), dtype=object)
data['sensorimotor'] = np.empty(len(words), dtype=object)


data_copy = {}
df = pd.DataFrame(data_copy)

for idx,word in enumerate(words):
    word_embedding = cls_tokens[idx] # Get the word embedding

    # construct vector for sensorimotor
    sensorimotor = []
    all_values = data.iloc[idx]
    mean_values = (all_values.iloc[1:12])/5 #setting them between 0-1
    for col,value in mean_values.items():
      sensorimotor.append(value)
    # data_copy = data.copy()  # Create a copy of the DataFrame
    # data_copy['sensorimotor'][idx] = sensorimotor  # Modify the copy
    # data.loc[idx] = data_copy.loc[idx]
    new_row = {'word': word, 'sensorimotor': sensorimotor,'embedding': word_embedding.cpu().detach().numpy()}
    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)



data = df
# delete all columns except sensorimotor and embedding


print(data)

# Save
torch.save(data, '/content/drive/My Drive/Lancaster/cls_tokens_roberta.pt')

"""## Creating Glove-Lancaster Dataset"""

# !wget http://nlp.stanford.edu/data/glove.6B.zip

# !unzip glove*.zip.1
# !ls
# !pwd

glove_embeddings_index = {}
f = open('glove.6B.100d.txt', encoding='utf-8')
for line in f:
    values = line.split()
    word = values[0]
    coefs = np.asarray(values[1:], dtype='float32')
    glove_embeddings_index[word] = coefs
f.close()

print('Found %s word vectors.' % len(glove_embeddings_index))

pickle.dump({'glove_embeddings_index' : glove_embeddings_index } , open('/content/drive/My Drive/Lancaster/glove_embeddings_index.pt', 'wb'))

# load
filename = "/content/drive/My Drive/Lancaster/glove_embeddings_index.pt"
with open(filename, 'rb') as file:
    loaded_embeddings = pickle.load(file)

glove_embeddings_index = loaded_embeddings.get('glove_embeddings_index', {})
print(len(glove_embeddings_index))

# Initialize a PyTorch embedding layer
vocab_size = len(glove_embeddings_index)
vector_size = len(glove_embeddings_index['apple'])
embedding = torch.nn.Embedding(vocab_size, vector_size)

    # Fill the embedding layer with the gensim weights
for i, word in enumerate(glove_embeddings_index):
    embedding.weight.data[i] = torch.tensor(glove_embeddings_index[word])


pytorch_embedding_glove = embedding

data = pd.read_csv('/content/drive/My Drive/Lancaster/lancaster-ensorimotor-norms.csv')

phrases = data['Word']
data['embedding'] = np.empty(len(phrases), dtype=object)
data['sensorimotor'] = np.empty(len(phrases), dtype=object)
data['word'] = np.empty(len(phrases), dtype=str)


data_copy = {}
df = pd.DataFrame(data_copy)

for idx,phrase in phrases.items():
  try:
        words = phrase.split()
        average_embedding = torch.zeros(pytorch_embedding_glove.embedding_dim)
        valid_word_count = 0
        for word in words:
          word_index = list(embeddings_index.keys()).index(word.lower()) # Get the index of the word
          word_index_tensor = torch.tensor(word_index)  # Convert the index to a PyTorch tensor
          word_embedding = pytorch_embedding_glove(word_index_tensor)  # Get the word embedding
          average_embedding += word_embedding
          valid_word_count += 1
        if valid_word_count > 0:
          average_embedding = average_embedding / valid_word_count
        else:
          average_embedding = None  # Handle case with no valid words
        # construct vector for sensorimotor
        sensorimotor = []
        all_values = data.iloc[idx]
        mean_values = (all_values.iloc[1:12])/5 #setting them between 0-1
        for col,value in mean_values.items():
          sensorimotor.append(value)
        # data_copy = data.copy()  # Create a copy of the DataFrame
        # data_copy['sensorimotor'][idx] = sensorimotor  # Modify the copy
        # data.loc[idx] = data_copy.loc[idx]
        new_row = {'word': word, 'sensorimotor': sensorimotor,'embedding': average_embedding.detach().numpy()}
        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)

  except ValueError:
        # Handle the case where the word is not in the word_vectors vocabulary
        # You can choose to skip it or use a default embedding in such cases
        print(f"Word '{word}' not found in the vocabulary.")


data = df

data_location = '/content/drive/My Drive/Lancaster/data_glove.pt'
torch.save(data, data_location)

"""## Creating intersection dataset"""

# Load word2vec data
filename = "/content/drive/My Drive/Lancaster/data.pt"
word2vec_data = torch.load(filename)

# Load glove data
filename = "/content/drive/My Drive/Lancaster/data_glove.pt"
glove_data = torch.load(filename)

# Load bert data
filename = "/content/drive/My Drive/Lancaster/cls_tokens.pt"
bert_data = torch.load(filename)

# Lists to store intersection rows
intersection_data_word2vec = []
intersection_data_glove = []
intersection_data_bert = []

# Find phrases they all have
for index, row in word2vec_data.iterrows():
    word = row['word']
    # Look for word in glove_data, bert_data
    results_glove = glove_data.loc[glove_data['word'] == word]
    results_bert = bert_data.loc[bert_data['word'] == word]

    if not results_glove.empty and not results_bert.empty:
        # Append rows to the lists
        intersection_data_word2vec.append(row)
        intersection_data_glove.append(results_glove.iloc[0])
        intersection_data_bert.append(results_bert.iloc[0])

# Create DataFrames from the lists
intersection_data_word2vec = pd.DataFrame(intersection_data_word2vec)
intersection_data_glove = pd.DataFrame(intersection_data_glove)
intersection_data_bert = pd.DataFrame(intersection_data_bert)

print(len(intersection_data_bert))
print(len(intersection_data_glove))
print(len(intersection_data_word2vec))

# Display the results
print("Intersection DataFrame for Glove:")
print(intersection_data_glove)

print("Intersection DataFrame for BERT:")
print(intersection_data_bert)

print("Intersection DataFrame for Word2Vec:")
print(intersection_data_word2vec)

# saving word2vec, glove, bert intersect data
location = "/content/drive/My Drive/Lancaster/intersect_word2vec.pt"
torch.save(intersection_data_word2vec, location)

location = "/content/drive/My Drive/Lancaster/intersect_glove.pt"
torch.save(intersection_data_glove, location)

location = "/content/drive/My Drive/Lancaster/intersect_cls_tokens.pt"
torch.save( intersection_data_bert, location)

import torch.nn.functional as F

# Ensure the output and target are on the same device and have the same dtype
out_tensor = out.squeeze(0) # Remove the batch dimension
target_tensor = torch.tensor(data['sensorimotor'][14356], dtype=out_tensor.dtype, device=device)

# Calculate cosine similarity
cos_sim = F.cosine_similarity(out_tensor, target_tensor, dim=0)
print("Cosine similarity:", cos_sim.item())